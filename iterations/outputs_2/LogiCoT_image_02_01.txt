1. The problem asks for the vector \(\mathbf{x}\) in standard coordinates given its coordinates in the basis \(B = \left\{ \begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix}, \begin{bmatrix} 2 \\ -1 \\ 1 \end{bmatrix} \right\}\) and coordinate vector \([\mathbf{x}]_B = \begin{bmatrix} 3 \\ 2 \end{bmatrix}\); by the definition of coordinate vectors, \(\mathbf{x} = 3\begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix} + 2\begin{bmatrix} 2 \\ -1 \\ 1 \end{bmatrix}\). 
2. Compute the linear combination: \(3\begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix} = \begin{bmatrix} 3 \\ 3 \\ 9 \end{bmatrix}\) and \(2\begin{bmatrix} 2 \\ -1 \\ 1 \end{bmatrix} = \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix}\); verify by scalar multiplication property. 
3. Add the two resulting vectors: \(\begin{bmatrix} 3 \\ 3 \\ 9 \end{bmatrix} + \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix} = \begin{bmatrix} 7 \\ 1 \\ 11 \end{bmatrix}\); verify by component-wise addition. 
4. The answer is \(\mathbf{x} = \begin{bmatrix} 7 \\ 1 \\ 11 \end{bmatrix}\).