1. To find the vector \(\mathbf{x}\) in standard coordinates, we use the formula \(\mathbf{x} = [\mathbf{x}]_B^1 \mathbf{b}_1 + [\mathbf{x}]_B^2 \mathbf{b}_2\), where \([\mathbf{x}]_B = \begin{bmatrix} 3 \\ 2 \end{bmatrix}\) and the basis vectors are \(\mathbf{b}_1 = \begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix}\), \(\mathbf{b}_2 = \begin{bmatrix} 2 \\ -1 \\ 1 \end{bmatrix}\). 
2. Substitute the values: \(\mathbf{x} = 3\begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix} + 2\begin{bmatrix} 2 \\ -1 \\ 1 \end{bmatrix}\). 
3. Multiply the scalars: \(3\begin{bmatrix} 1 \\ 1 \\ 3 \end{bmatrix} = \begin{bmatrix} 3 \\ 3 \\ 9 \end{bmatrix}\) and \(2\begin{bmatrix} 2 \\ -1 \\ 1 \end{bmatrix} = \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix}\). 
4. Add the resulting vectors: \(\begin{bmatrix} 3 \\ 3 \\ 9 \end{bmatrix} + \begin{bmatrix} 4 \\ -2 \\ 2 \end{bmatrix} = \begin{bmatrix} 7 \\ 1 \\ 11 \end{bmatrix}\). 
5. Therefore, the vector \(\mathbf{x}\) in standard coordinates is \(\boxed{\begin{bmatrix} 7 \\ 1 \\ 11 \end{bmatrix}}\).